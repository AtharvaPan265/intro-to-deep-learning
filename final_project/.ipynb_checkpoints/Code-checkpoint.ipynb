{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5449d191",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d958ffb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd00832",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "572c31ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9400 files for training\n",
      "Input shape: torch.Size([9400, 62, 12])\n",
      "Target shape: torch.Size([9400, 5, 12])\n",
      "Training set: torch.Size([6583, 62, 12]), torch.Size([6583, 5, 12])\n",
      "Validation set: torch.Size([1407, 62, 12]), torch.Size([1407, 5, 12])\n",
      "Test set: torch.Size([1410, 62, 12]), torch.Size([1410, 5, 12])\n"
     ]
    }
   ],
   "source": [
    "data_directory = \"data/Car_data/car_data\" \n",
    "\n",
    "X_data = []  \n",
    "y_data = []  \n",
    "\n",
    "for filename in os.listdir(data_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(data_directory, filename)\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        file_data = df.values\n",
    "        \n",
    "        if len(file_data) >= 67: \n",
    "            X_data.append(file_data[:62])\n",
    "            y_data.append(file_data[62:67])  \n",
    "        else:\n",
    "            print(f\"Warning: File {filename} has fewer than 67 rows and will be skipped.\")\n",
    "\n",
    "X_tensor = torch.FloatTensor(np.array(X_data))  \n",
    "y_tensor = torch.FloatTensor(np.array(y_data))  \n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Loaded {len(X_data)} files for training\")\n",
    "print(f\"Input shape: {X_tensor.shape}\")\n",
    "print(f\"Target shape: {y_tensor.shape}\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split data into temp (train+validation) and test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_tensor.numpy(), y_tensor.numpy(), \n",
    "                                                  test_size=0.15, random_state=42)\n",
    "\n",
    "# Then split the temp data into train and validation\n",
    "# 0.176 of 85% is ~15% of the original dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, \n",
    "                                                  test_size=0.176, random_state=42)  \n",
    "\n",
    "# Convert back to tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "y_val_tensor = torch.FloatTensor(y_val)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training set: {X_train_tensor.shape}, {y_train_tensor.shape}\")\n",
    "print(f\"Validation set: {X_val_tensor.shape}, {y_val_tensor.shape}\")\n",
    "print(f\"Test set: {X_test_tensor.shape}, {y_test_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3922c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_custom(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size=12,\n",
    "        hidden_size=64,\n",
    "        dropout=0.2,\n",
    "    ):\n",
    "        super(LSTM_custom, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout_rate = dropout\n",
    "        self.projection_layer = nn.Linear(self.hidden_size, input_size)\n",
    "        self.dropout = nn.Dropout(dropout)  # Add dropout layer\n",
    "\n",
    "        # Input gate\n",
    "        self.W_xi = nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(input_size, hidden_size)))\n",
    "        self.b_xi = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.W_hi = nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(hidden_size, hidden_size)))\n",
    "        self.b_hi = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "        # Forget gate\n",
    "        self.W_xf = nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(input_size, hidden_size)))\n",
    "        self.b_xf = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.W_hf = nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(hidden_size, hidden_size)))\n",
    "        self.b_hf = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "        # Cell gate\n",
    "        self.W_xg = nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(input_size, hidden_size)))\n",
    "        self.b_xg = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.W_hg = nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(hidden_size, hidden_size)))\n",
    "        self.b_hg = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "        # Output gate\n",
    "        self.W_xo = nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(input_size, hidden_size)))\n",
    "        self.b_xo = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.W_ho = nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(hidden_size, hidden_size)))\n",
    "        self.b_ho = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "    def input_gate(self, x_t, h_prev):\n",
    "        return torch.sigmoid(\n",
    "            torch.matmul(x_t, self.W_xi) + self.b_xi + torch.matmul(h_prev, self.W_hi) + self.b_hi\n",
    "        )\n",
    "\n",
    "    def forget_gate(self, x_t, h_prev):\n",
    "        return torch.sigmoid(\n",
    "            torch.matmul(x_t, self.W_xf) + self.b_xf + torch.matmul(h_prev, self.W_hf) + self.b_hf\n",
    "        )\n",
    "\n",
    "    def cell_gate(self, x_t, h_prev):\n",
    "        return torch.tanh(\n",
    "            torch.matmul(x_t, self.W_xg) + self.b_xg + torch.matmul(h_prev, self.W_hg) + self.b_hg\n",
    "        )\n",
    "\n",
    "    def output_gate(self, x_t, h_prev):\n",
    "        return torch.sigmoid(\n",
    "            torch.matmul(x_t, self.W_xo) + self.b_xo + torch.matmul(h_prev, self.W_ho) + self.b_ho\n",
    "        )\n",
    "\n",
    "    def lstm_cell(self, x_t, h_prev, c_prev):\n",
    "        i_t = self.input_gate(x_t, h_prev)\n",
    "        f_t = self.forget_gate(x_t, h_prev)\n",
    "        g_t = self.cell_gate(x_t, h_prev)\n",
    "        o_t = self.output_gate(x_t, h_prev)\n",
    "\n",
    "        c_t = f_t * c_prev + i_t * g_t\n",
    "        h_t = o_t * torch.tanh(c_t)\n",
    "        h_t = self.dropout(h_t)\n",
    "        return h_t, c_t\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, feature_dim = x.size()\n",
    "        h_t = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "        c_t = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            h_t, c_t = self.lstm_cell(x[:, t, :], h_t, c_t)\n",
    "\n",
    "        predictions = []\n",
    "        current_x = x[:, -1, :]  \n",
    "        for i in range(5):\n",
    "            h_t, c_t = self.lstm_cell(current_x, h_t, c_t)\n",
    "            output = self.projection_layer(h_t)\n",
    "            predictions.append(output)\n",
    "            current_x = output  \n",
    "        return torch.stack(predictions, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2785745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSELoss(y_pred, y_true):\n",
    "    return torch.sqrt(nn.MSELoss()(y_pred, y_true) + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ce829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  train_model(name, input_size=12, hidden_size=64, dropout=0.2, lr= 0.01, num_epochs=100):\n",
    "    model = LSTM_custom(input_size=input_size, hidden_size=hidden_size, dropout=dropout).to(device)\n",
    "    criterion = RMSELoss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    learning_rates = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for inputs, targets in train_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "               \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_dataloader)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in val_dataloader:\n",
    "                    inputs = inputs.to(device)\n",
    "                    targets = targets.to(device)\n",
    "                    \n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "            avg_val_loss = val_loss / len(val_dataloader)\n",
    "        else:\n",
    "            avg_val_loss = None\n",
    "        \n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        learning_rates.append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "                f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "                f\"Val Loss: {avg_val_loss:.4f}, \"\n",
    "                f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, 'b-', label='Training Loss')\n",
    "    val_epochs = [i for i, v in enumerate(val_losses) if v is not None]\n",
    "    val_losses_filtered = [v for v in val_losses if v is not None]\n",
    "    plt.plot(val_epochs, val_losses_filtered, 'r-', label='Validation Loss')\n",
    "    plt.title(f'Training and Validation Loss for {name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "443c067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "def test_model(name, model, test_dataloader):\n",
    "    criterion = RMSELoss\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for inputs, targets in test_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            test_loss += criterion(outputs, targets).item()\n",
    "        \n",
    "        avg_test_loss = test_loss / len(test_dataloader)\n",
    "        print(f\"Test Loss for {name}: {avg_test_loss:.4f}\")\n",
    "    return avg_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fbbab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_model(name, input_size=12, hidden_size=64, dropout=0.2, lr= 0.01, num_epochs=100):\n",
    "    model = train_model(name, input_size=input_size, hidden_size=hidden_size, dropout=dropout, lr=lr, num_epochs=num_epochs)\n",
    "    return test_model(name, model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30135c8",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd9013af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train Loss: 119.9165, Val Loss: 120.2651, LR: 0.009755\n",
      "Epoch [20/100], Train Loss: 118.3098, Val Loss: 118.6043, LR: 0.009045\n",
      "Epoch [30/100], Train Loss: 116.8165, Val Loss: 117.1152, LR: 0.007939\n",
      "Epoch [40/100], Train Loss: 115.3774, Val Loss: 115.8155, LR: 0.006545\n",
      "Epoch [50/100], Train Loss: 114.3785, Val Loss: 114.7260, LR: 0.005000\n",
      "Epoch [60/100], Train Loss: 113.6159, Val Loss: 113.9265, LR: 0.003455\n",
      "Epoch [70/100], Train Loss: 112.9795, Val Loss: 113.3855, LR: 0.002061\n",
      "Epoch [80/100], Train Loss: 112.7756, Val Loss: 113.1046, LR: 0.000955\n",
      "Epoch [90/100], Train Loss: 112.6331, Val Loss: 112.9815, LR: 0.000245\n",
      "Epoch [100/100], Train Loss: 112.5839, Val Loss: 112.9624, LR: 0.000000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nam67e' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test_results[\u001b[33m\"\u001b[39m\u001b[33m512 | 0.2 | 0.01 | 100\u001b[39m\u001b[33m\"\u001b[39m] =  \u001b[43mtrain_and_test_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m512 | 0.2 | 0.01 | 100\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mtrain_and_test_model\u001b[39m\u001b[34m(name, input_size, hidden_size, dropout, lr, num_epochs)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_and_test_model\u001b[39m(name, input_size=\u001b[32m12\u001b[39m, hidden_size=\u001b[32m64\u001b[39m, dropout=\u001b[32m0.2\u001b[39m, lr= \u001b[32m0.01\u001b[39m, num_epochs=\u001b[32m100\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     model = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m test_model(name, model, test_dataloader)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(name, input_size, hidden_size, dropout, lr, num_epochs)\u001b[39m\n\u001b[32m     61\u001b[39m val_losses_filtered = [v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m val_losses \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m     62\u001b[39m plt.plot(val_epochs, val_losses_filtered, \u001b[33m'\u001b[39m\u001b[33mr-\u001b[39m\u001b[33m'\u001b[39m, label=\u001b[33m'\u001b[39m\u001b[33mValidation Loss\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m plt.title(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTraining and Validation Loss for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mnam67e\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     64\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mEpochs\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     65\u001b[39m plt.ylabel(\u001b[33m'\u001b[39m\u001b[33mLoss\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'nam67e' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_results[\"512 | 0.2 | 0.01 | 100\"] =  train_and_test_model(\"512 | 0.2 | 0.01 | 100\", input_size=12, hidden_size=512, dropout=0.2, lr=0.01, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdda952",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results[\"512 | 0.2 | 0.001 | 100\"] =  train_and_test_model(\"512 | 0.2 | 0.001 | 100\", input_size=12, hidden_size=512, dropout=0.2, lr=0.001, num_epochs=100)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a89e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results[\"1024 | 0.2 | 0.001 | 100\"] =  train_and_test_model(\"1024 | 0.2 | 0.001 | 100\", input_size=12, hidden_size=1024, dropout=0.2, lr=0.001, num_epochs=100)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in test_results.items():\n",
    "    print(f\"Test Loss for {k}: {v:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
