{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3kLIesLuEkg",
        "outputId": "29d5c7ec-e06c-4fb5-944b-32f4ad36de7f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = '/content/drive/MyDrive/car_data'\n",
        "all_files = sorted([os.path.join(DATA_DIR, f) for f in os.listdir(DATA_DIR) if f.endswith('.csv')])\n",
        "files = all_files[:13000]  # Change to 'all_files' to use full dataset\n",
        "\n",
        "def load_and_split(path, input_len=62, pred_len=5, features=None):\n",
        "    df = pd.read_csv(path)\n",
        "    if features is None:\n",
        "        features = df.columns.tolist()\n",
        "    data = df[features].values\n",
        "    x = data[:input_len]\n",
        "    y = data[input_len:input_len+pred_len, :2]\n",
        "    return x, y\n",
        "\n",
        "# Build datasets\n",
        "X_list, Y_list = [], []\n",
        "for fp in tqdm(files, desc=\"Loading data\"):\n",
        "    x, y = load_and_split(fp)\n",
        "    X_list.append(x)\n",
        "    Y_list.append(y)\n",
        "X = np.stack(X_list)  # (N, T, D)\n",
        "Y = np.stack(Y_list)  # (N, pred_len, 2)\n",
        "\n",
        "# Shuffle and split 80/10/10\n",
        "N = X.shape[0]\n",
        "idx = np.arange(N)\n",
        "np.random.shuffle(idx)\n",
        "n_train = int(0.8 * N)\n",
        "n_val   = int(0.1 * N)\n",
        "\n",
        "train_idx = idx[:n_train]\n",
        "val_idx   = idx[n_train:n_train+n_val]\n",
        "test_idx  = idx[n_train+n_val:]\n",
        "\n",
        "X_train, Y_train = X[train_idx], Y[train_idx]\n",
        "X_val,   Y_val   = X[val_idx],   Y[val_idx]\n",
        "X_test,  Y_test  = X[test_idx],  Y[test_idx]\n",
        "\n",
        "# Normalize using train stats\n",
        "X_mean = X_train.mean(axis=(0, 1), keepdims=True)\n",
        "X_std  = X_train.std(axis=(0, 1), keepdims=True) + 1e-6\n",
        "X_train_norm = (X_train - X_mean) / X_std\n",
        "X_val_norm   = (X_val   - X_mean) / X_std\n",
        "X_test_norm  = (X_test  - X_mean) / X_std\n",
        "\n",
        "# Normalize output coordinates (Local_X and Local_Y)\n",
        "coord_mean = Y_train.mean(axis=(0, 1), keepdims=True)  # shape (1, 1, 2)\n",
        "coord_std  = Y_train.std(axis=(0, 1), keepdims=True) + 1e-6\n",
        "\n",
        "Y_train_norm = (Y_train - coord_mean) / coord_std\n",
        "Y_val_norm   = (Y_val   - coord_mean) / coord_std\n",
        "Y_test_norm  = (Y_test  - coord_mean) / coord_std\n",
        "\n",
        "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo8EMdCOwjc5",
        "outputId": "e2cde3a8-4609-4dd9-d0a4-072a42ea70ca"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading data: 100%|██████████| 9402/9402 [02:27<00:00, 63.93it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (7521, 62, 12), Val: (940, 62, 12), Test: (941, 62, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ManualLSTMCell:\n",
        "    def __init__(self, input_dim, hidden_dim, lr):\n",
        "        D, H = input_dim, hidden_dim\n",
        "        self.lr = lr\n",
        "\n",
        "        # Weight matrices\n",
        "        self.Wf = np.random.randn(H, H + D) * 0.1\n",
        "        self.Wi = np.random.randn(H, H + D) * 0.1\n",
        "        self.Wc = np.random.randn(H, H + D) * 0.1\n",
        "        self.Wo = np.random.randn(H, H + D) * 0.1\n",
        "\n",
        "        # Biases\n",
        "        self.bf = np.zeros((H, 1))\n",
        "        self.bi = np.zeros((H, 1))\n",
        "        self.bc = np.zeros((H, 1))\n",
        "        self.bo = np.zeros((H, 1))\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(x):\n",
        "        pos = (x >= 0)\n",
        "        neg = ~pos\n",
        "        out = np.empty_like(x, dtype=float)\n",
        "        out[pos] = 1.0 / (1.0 + np.exp(-x[pos]))\n",
        "        exp_x = np.exp(x[neg])\n",
        "        out[neg] = exp_x / (1.0 + exp_x)\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def dsigmoid(y):\n",
        "        return y * (1 - y)\n",
        "\n",
        "    @staticmethod\n",
        "    def dtanh(y):\n",
        "        return 1 - y**2\n",
        "\n",
        "    def forward(self, x_seq):\n",
        "        T, D = x_seq.shape\n",
        "        H = self.bf.shape[0]\n",
        "\n",
        "        h_prev = np.zeros((H, 1))\n",
        "        c_prev = np.zeros((H, 1))\n",
        "\n",
        "        hs, cs, caches = [], [], []\n",
        "\n",
        "        for t in range(T):\n",
        "            x_t = x_seq[t].reshape(-1, 1)\n",
        "            concat = np.vstack((h_prev, x_t))\n",
        "\n",
        "            f_t = self.sigmoid(self.Wf @ concat + self.bf)\n",
        "            i_t = self.sigmoid(self.Wi @ concat + self.bi)\n",
        "            c_hat_t = np.tanh(self.Wc @ concat + self.bc)\n",
        "            c_t = f_t * c_prev + i_t * c_hat_t\n",
        "            o_t = self.sigmoid(self.Wo @ concat + self.bo)\n",
        "            h_t = o_t * np.tanh(c_t)\n",
        "\n",
        "            hs.append(h_t)\n",
        "            cs.append(c_t)\n",
        "            caches.append((concat, f_t, i_t, c_hat_t, o_t, c_prev, c_t))\n",
        "\n",
        "            h_prev, c_prev = h_t, c_t\n",
        "\n",
        "        return hs, cs, caches\n",
        "\n",
        "    def backward(self, dh_next, dc_next, caches):\n",
        "      # Initialize gradients\n",
        "      dWf = np.zeros_like(self.Wf)\n",
        "      dWi = np.zeros_like(self.Wi)\n",
        "      dWc = np.zeros_like(self.Wc)\n",
        "      dWo = np.zeros_like(self.Wo)\n",
        "      dbf = np.zeros_like(self.bf)\n",
        "      dbi = np.zeros_like(self.bi)\n",
        "      dbc = np.zeros_like(self.bc)\n",
        "      dbo = np.zeros_like(self.bo)\n",
        "\n",
        "      dh, dc = dh_next.copy(), dc_next.copy()\n",
        "      H = self.bf.shape[0]\n",
        "\n",
        "      for t in reversed(range(len(caches))):\n",
        "          concat, f_t, i_t, c_hat_t, o_t, c_prev, c_t = caches[t]\n",
        "\n",
        "          tanh_c_t = np.tanh(c_t)\n",
        "          do = dh * tanh_c_t\n",
        "          dao = do * self.dsigmoid(o_t)\n",
        "\n",
        "          dc_raw = dc + dh * o_t * self.dtanh(tanh_c_t)\n",
        "\n",
        "          df = dc_raw * c_prev\n",
        "          di = dc_raw * c_hat_t\n",
        "          dc_hat = dc_raw * i_t\n",
        "\n",
        "          daf = df * self.dsigmoid(f_t)\n",
        "          dai = di * self.dsigmoid(i_t)\n",
        "          dac = dc_hat * self.dtanh(c_hat_t)\n",
        "\n",
        "          dWf += daf @ concat.T\n",
        "          dWi += dai @ concat.T\n",
        "          dWc += dac @ concat.T\n",
        "          dWo += dao @ concat.T\n",
        "          dbf += daf\n",
        "          dbi += dai\n",
        "          dbc += dac\n",
        "          dbo += dao\n",
        "\n",
        "          dconcat = (\n",
        "              self.Wf.T @ daf +\n",
        "              self.Wi.T @ dai +\n",
        "              self.Wc.T @ dac +\n",
        "              self.Wo.T @ dao\n",
        "          )\n",
        "          dh = dconcat[:H, :]\n",
        "          dc = dc_raw * f_t\n",
        "\n",
        "      # Apply gradient descent step\n",
        "      for param, dparam in [\n",
        "          (self.Wf, dWf), (self.Wi, dWi), (self.Wc, dWc), (self.Wo, dWo),\n",
        "          (self.bf, dbf), (self.bi, dbi), (self.bc, dbc), (self.bo, dbo)\n",
        "      ]:\n",
        "          param -= self.lr * dparam\n",
        "\n"
      ],
      "metadata": {
        "id": "PNSaMUnqjX0Y"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "INPUT_DIM  = X_train.shape[2]\n",
        "HIDDEN_DIM = 64\n",
        "EPOCHS     = 20\n",
        "LR         = 0.001\n",
        "\n",
        "cell  = ManualLSTMCell(INPUT_DIM, HIDDEN_DIM, lr=LR)\n",
        "W_out = np.random.randn(2*5, HIDDEN_DIM) * 0.1\n",
        "b_out = np.zeros((2*5,1))\n",
        "\n",
        "train_rmse, val_rmse = [], []\n",
        "train_start = time.time()\n",
        "\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    epoch_start = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    # --- Training pass ---\n",
        "    for x_seq, y_true in zip(X_train_norm, Y_train):\n",
        "        hs, cs, caches = cell.forward(x_seq)\n",
        "        h_T = hs[-1]\n",
        "        y_pred = (W_out @ h_T + b_out).reshape(5,2)\n",
        "        err = y_pred - y_true\n",
        "        loss = np.sqrt((err**2).mean())\n",
        "        total_loss += loss\n",
        "\n",
        "        # backward on output\n",
        "        dy = 2 * err / (5*2)\n",
        "        dy = dy.reshape(10,1)\n",
        "        dW_out = dy @ h_T.T\n",
        "        db_out = dy\n",
        "        W_out  -= LR * dW_out\n",
        "        b_out  -= LR * db_out\n",
        "\n",
        "        dh  = W_out.T @ dy\n",
        "        dc0 = np.zeros_like(cs[0])\n",
        "        cell.backward(dh, dc0, caches)\n",
        "\n",
        "    avg_train = total_loss / len(X_train_norm)\n",
        "    train_rmse.append(avg_train)\n",
        "\n",
        "    # --- Validation pass (no weight updates) ---\n",
        "    tot_val = 0\n",
        "    for x_seq, y_true in zip(X_val_norm, Y_val):\n",
        "        hs, _, _ = cell.forward(x_seq)\n",
        "        y_pred = (W_out @ hs[-1] + b_out).reshape(5,2)\n",
        "        tot_val += np.sqrt(((y_pred - y_true)**2).mean())\n",
        "    avg_val = tot_val / len(X_val_norm)\n",
        "    val_rmse.append(avg_val)\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    print(f\"Epoch {ep:2d} — train RMSE: {avg_train:.4f} — val RMSE: {avg_val:.4f} — {epoch_time:.1f}s\")\n",
        "\n",
        "total_time = time.time() - train_start\n",
        "print(f\"\\nTotal training time: {total_time:.1f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "S2ss8VkMjYo5",
        "outputId": "aa4f989a-75e3-46a8-84ea-97153b502074"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 — train RMSE: 284.9539 — val RMSE: 209.4570 — 132.9s\n",
            "Epoch  2 — train RMSE: 187.1766 — val RMSE: 168.7946 — 130.7s\n",
            "Epoch  3 — train RMSE: 170.6001 — val RMSE: 167.7523 — 131.0s\n",
            "Epoch  4 — train RMSE: 158.5760 — val RMSE: 158.9072 — 130.4s\n",
            "Epoch  5 — train RMSE: 175.6770 — val RMSE: 171.3334 — 130.0s\n",
            "Epoch  6 — train RMSE: 166.1900 — val RMSE: 158.1724 — 129.2s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-dbcd8fbc6c28>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mdh\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mW_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mdc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdc0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mavg_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-60e1bf376398>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dh_next, dc_next, caches)\u001b[0m\n\u001b[1;32m    113\u001b[0m                        self.Wo.T @ dao)\n\u001b[1;32m    114\u001b[0m             \u001b[0mdh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdconcat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mdc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# Gradient descent step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "test_preds = []\n",
        "for x_seq in X_test_norm:\n",
        "    hs, _, _ = cell.forward(x_seq)\n",
        "    h_last = hs[-1]\n",
        "    y_hat = (W_out @ h_last + b_out).reshape(-1)\n",
        "    test_preds.append(y_hat)\n",
        "\n",
        "test_preds = np.array(test_preds).reshape(len(X_test), 5, 2)  # reshape to match Y_test\n",
        "test_rmse = np.sqrt(((test_preds - Y_test)**2).mean())\n",
        "print(f\"Test RMSE: {test_rmse:.4f}\")"
      ],
      "metadata": {
        "id": "ntNv3ThXjbCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot RMSE curves\n",
        "plt.plot(train_rmse, label='Train RMSE')\n",
        "plt.plot(val_rmse,   label='Val RMSE')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.title(\"Train vs. Val RMSE\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OSkXNZ9ejdZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_gap = [tr - val for tr, val in zip(train_rmse, val_rmse)]\n",
        "\n",
        "plt.plot(rmse_gap, label=\"Train - Val RMSE Gap\")\n",
        "plt.axhline(0, color='gray', linestyle='--')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"RMSE Gap\")\n",
        "plt.title(\"Training vs Validation RMSE Gap\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FxMLLZmijfT9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}