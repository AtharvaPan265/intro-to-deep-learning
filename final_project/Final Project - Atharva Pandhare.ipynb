{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf03dff",
   "metadata": {},
   "source": [
    "# LSTM Cell Writeup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e97f3",
   "metadata": {},
   "source": [
    "# LSTM Cell Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3136cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Data directory\n",
    "csv_dir = \"data/Car_data/car_data\"\n",
    "print(f\"Data directory: {csv_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb5047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all CSV files\n",
    "csv_files = [os.path.join(csv_dir, f)\n",
    "             for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
    "\n",
    "# List all CSV files\n",
    "\n",
    "print(f\"Total files: {len(csv_files)}\")\n",
    "\n",
    "# Split into train/test sets\n",
    "data_80 = int(len(csv_files) * 0.8)\n",
    "trainset = csv_files[:data_80]\n",
    "testset = csv_files[data_80:]\n",
    "print(f\"Training files: {len(trainset)}\")\n",
    "print(f\"Testing files: {len(testset)}\")\n",
    "print(f\"Verification: {(len(trainset) + len(testset)) == len(csv_files)}\")\n",
    "\n",
    "# Fit scaler on all training data\n",
    "all_train_data = []\n",
    "for file_path in trainset:\n",
    "    df = pd.read_csv(file_path)\n",
    "    all_train_data.append(df.values)\n",
    "\n",
    "all_train_data = np.vstack(all_train_data)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(all_train_data)\n",
    "\n",
    "# Lists to store sequences\n",
    "all_sequences = []\n",
    "\n",
    "# Process each file\n",
    "for file_path in trainset:\n",
    "    # Read CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Scale the data\n",
    "    scaled_data = scaler.transform(df.values)\n",
    "\n",
    "    # Store the sequence\n",
    "    all_sequences.append(scaled_data)\n",
    "\n",
    "# Create input/output sequences\n",
    "X = []  # Input: 62 time steps, all 12 features\n",
    "y = []  # Output: next 5 time steps, only x,y coordinates\n",
    "\n",
    "for sequence in all_sequences:\n",
    "    # Only use sequences with enough time steps\n",
    "    if len(sequence) >= 67:\n",
    "        for i in range(len(sequence) - 67 + 1):\n",
    "            # 62 time steps as input, all features\n",
    "            X.append(sequence[i:i+62, :])\n",
    "            # next 5 time steps, only x,y coordinates\n",
    "            y.append(sequence[i+62:i+67, :2])\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(np.array(X), dtype=torch.float32)\n",
    "y = torch.tensor(np.array(y), dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(X, y)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                          shuffle=False, pin_memory=True, num_workers=12\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2853532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LSTM_custom(nn.Module):\n",
    "#     def __init__(self, input_size=12, hidden_size=64, num_layers=1, sequence_length=10, dropout=0.2):\n",
    "\n",
    "#         super(LSTM_custom, self).__init__()\n",
    "#         self.input_size = input_size\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "\n",
    "#         # Input gate\n",
    "#         self.W_xi = nn.Linear(input_size, hidden_size)\n",
    "#         self.W_hi = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "#         # Forget gate\n",
    "#         self.W_xf = nn.Linear(input_size, hidden_size)\n",
    "#         self.W_hf = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "#         # Cell gate\n",
    "#         self.W_xg = nn.Linear(input_size, hidden_size)\n",
    "#         self.W_hg = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "#         # Output gate\n",
    "#         self.W_xo = nn.Linear(input_size, hidden_size)\n",
    "#         self.W_ho = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "#     def lstm_cell(self, x_t, h_prev, c_prev):\n",
    "#         i_t = torch.sigmoid(self.W_xi(x_t) + self.W_hi(h_prev))\n",
    "#         f_t = torch.sigmoid(self.W_xf(x_t) + self.W_hf(h_prev))\n",
    "#         g_t = torch.tanh(self.W_xg(x_t) + self.W_hg(h_prev))\n",
    "#         o_t = torch.sigmoid(self.W_xo(x_t) + self.W_ho(h_prev))\n",
    "\n",
    "#         c_t = f_t * c_prev + i_t * g_t\n",
    "#         h_t = o_t * torch.tanh(c_t)\n",
    "\n",
    "#         return h_t, c_t\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         batch_size, seq_len, _ = x.size()\n",
    "#         h_t = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "#         c_t = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "        \n",
    "#         # Process the input sequence once\n",
    "#         for t in range(seq_len):\n",
    "#             h_t, c_t = self.lstm_cell(x[:, t, :], h_t, c_t)\n",
    "        \n",
    "#         # Predict next 5 timesteps\n",
    "#         predictions = []\n",
    "#         current_x = x[:, -1, :]  # Start with the last input\n",
    "        \n",
    "#         for i in range(5):\n",
    "#             h_t, c_t = self.lstm_cell(current_x, h_t, c_t)\n",
    "#             predictions.append(h_t)\n",
    "#             # You would need a projection layer to convert h_t to the right dimension\n",
    "#             # current_x = projection_layer(h_t)\n",
    "        \n",
    "#         return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356c2184",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_custom(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size=12,\n",
    "        hidden_size=64,\n",
    "        num_layers=1,\n",
    "        sequence_length=10,\n",
    "        dropout=0.2,\n",
    "    ):\n",
    "\n",
    "        super(LSTM_custom, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Input gate\n",
    "\n",
    "        ## Weights for input\n",
    "        self.b_xi\n",
    "        self.W_xi\n",
    "        ## Weights for hidden state\n",
    "        self.W_hi\n",
    "        self.b_hi\n",
    "\n",
    "        # Forget gate\n",
    "        ## Weights for input\n",
    "        self.W_xf\n",
    "        self.b_xf\n",
    "        ## Weights for hidden state\n",
    "        self.W_hf\n",
    "        self.b_hf\n",
    "\n",
    "        # Cell gate\n",
    "        ## Weights for input\n",
    "        self.W_xg\n",
    "        self.b_xg\n",
    "        ## Weights for hidden state\n",
    "        self.W_hg\n",
    "        self.b_hg\n",
    "\n",
    "        # Output gate\n",
    "        ## Weights for input\n",
    "        self.W_xo\n",
    "        self.b_xo\n",
    "        ## Weights for hidden state\n",
    "        self.W_ho\n",
    "        self.b_ho\n",
    "\n",
    "    def input_gate(self, x_t, h_prev):\n",
    "        return torch.sigmoid(\n",
    "            (self.W_xi @ x_t + self.b_xi) + (self.W_hi @ h_prev + self.b_hi)\n",
    "        )\n",
    "\n",
    "    def forget_gate(self, x_t, h_prev):\n",
    "        return torch.sigmoid(\n",
    "            (self.W_xf @ x_t + self.b_xf) + (self.W_hf @ h_prev + self.b_hf)\n",
    "        )\n",
    "\n",
    "    def cell_gate(self, x_t, h_prev):\n",
    "        return torch.tanh(\n",
    "            (self.W_xg @ x_t + self.b_xg) + (self.W_hg @ h_prev + self.b_hg)\n",
    "        )\n",
    "\n",
    "    def output_gate(self, x_t, h_prev):\n",
    "        return torch.sigmoid(\n",
    "            (self.W_xo @ x_t + self.b_xo) + (self.W_ho @ h_prev + self.b_ho)\n",
    "        )\n",
    "\n",
    "    def lstm_cell(self, x_t, h_prev, c_prev):\n",
    "        i_t = self.input_gate(x_t, h_prev)\n",
    "        f_t = self.forget_gate(x_t, h_prev)\n",
    "        g_t = self.cell_gate(x_t, h_prev)\n",
    "        o_t = self.output_gate(x_t, h_prev)\n",
    "\n",
    "        c_t = f_t * c_prev + i_t * g_t\n",
    "        h_t = o_t * torch.tanh(c_t)\n",
    "\n",
    "        return h_t, c_t\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        h_t = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "        c_t = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "\n",
    "        # Process the input sequence once\n",
    "        for t in range(seq_len):\n",
    "            h_t, c_t = self.lstm_cell(x[:, t, :], h_t, c_t)\n",
    "\n",
    "        # Predict next 5 timesteps\n",
    "        predictions = []\n",
    "        current_x = x[:, -1, :]  # Start with the last input\n",
    "\n",
    "        for i in range(5):\n",
    "            h_t, c_t = self.lstm_cell(current_x, h_t, c_t)\n",
    "            predictions.append(h_t)\n",
    "            # You would need a projection layer to convert h_t to the right dimension\n",
    "            # current_x = projection_layer(h_t)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f13b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_loss(y_pred, y_true):\n",
    "    return torch.sqrt(torch.mean((y_pred - y_true) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476d37ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "input_size = 12  # Number of input features (still use all features as input)\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "model = LSTM_custom(input_size=input_size, hidden_size=hidden_size,\n",
    "                    num_layers=num_layers).to(device)\n",
    "# Loss and optimizer\n",
    "\n",
    "criterion = rmse_loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c60ab94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa594c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        print(inputs.shape)\n",
    "        print(targets.shape)\n",
    "        break\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs[-1], targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
