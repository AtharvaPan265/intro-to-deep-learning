{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "489933df",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "**Author:** Atharva Pandhare\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccf9641",
   "metadata": {},
   "source": [
    "## Imports and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4e2492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in relevant libraries, and alias where appropriate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "\n",
    "# Define relevant variables for the ML task\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "num_epochs = 20\n",
    "\n",
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c7d6b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training data\n",
    "cifar_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# For test data\n",
    "cifar_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf4194b",
   "metadata": {},
   "source": [
    "## Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95e483",
   "metadata": {},
   "source": [
    "### LeNet Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195405cb",
   "metadata": {},
   "source": [
    "|name|output size|\n",
    "|---|---|\n",
    "|Input|32x32x3|\n",
    "|conv(kernel = 5, output channels = 6)|28x28x6|\n",
    "|MaxPool(window = 2)|16x16x6|\n",
    "|conv(kernel = 5, output channels = 16)|12x12x16|\n",
    "|MaxPool(window = 2)|6x6x16|\n",
    "|linear|120|\n",
    "|linear|84|\n",
    "|linear|10|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109cc752",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(out_channels=6, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.LazyConv2d(out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.LazyLinear(out_features=120),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.LazyLinear(out_features=84),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.LazyLinear(out_features=10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.net(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07cbaae",
   "metadata": {},
   "source": [
    "### LeNet Architecture with Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2d6aaa",
   "metadata": {},
   "source": [
    "|name|output size|\n",
    "|---|---|\n",
    "|Input|32x32x3|\n",
    "|conv(kernel = 5, output channels = 6)|28x28x6|\n",
    "|MaxPool(window = 2)|16x16x6|\n",
    "|conv(kernel = 5, output channels = 16)|12x12x16|\n",
    "|MaxPool(window = 2)|6x6x16|\n",
    "|linear|120|\n",
    "|Dropout|120|\n",
    "|linear|84|\n",
    "|linear|10|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b48dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet_v1(nn.Module):\n",
    "    def __init__(self, conv_dropout_rate = 0.2, fc_dropout_rate=0.5):\n",
    "        super(LeNet_v1, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(out_channels=6, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.LazyConv2d(out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.LazyLinear(out_features=120),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Dropout(fc_dropout_rate),\n",
    "\n",
    "            nn.LazyLinear(out_features=84),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.LazyLinear(out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.net(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f61b47",
   "metadata": {},
   "source": [
    "### LeNet Architecture with Dropout and Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0841a6",
   "metadata": {},
   "source": [
    "|name|output size|\n",
    "|---|---|\n",
    "|Input|32x32x3|\n",
    "|conv(kernel = 5, output channels = 6)|28x28x6|\n",
    "|Batch Normalization|28x28x6|\n",
    "|MaxPool(window = 2)|16x16x6|\n",
    "|conv(kernel = 5, output channels = 16)|12x12x16|\n",
    "|MaxPool(window = 2)|6x6x16|\n",
    "|linear|120|\n",
    "|Dropout|120|\n",
    "|linear|84|\n",
    "|linear|10|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cb6d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet_v2(nn.Module):\n",
    "    def __init__(self, fc_dropout_rate=0.5):\n",
    "        super(LeNet_v2, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(out_channels=6, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.LazyConv2d(out_channels=16, kernel_size=5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.LazyLinear(out_features=120),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Dropout(fc_dropout_rate),\n",
    "\n",
    "            nn.LazyLinear(out_features=84),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.LazyLinear(out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.net(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5643aa9",
   "metadata": {},
   "source": [
    "## Train and Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e61314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, num_epochs = num_epochs):\n",
    "    start_time = time.time()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set model to training mode\n",
    "        model.train()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            # Move data to device (CPU/GPU)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:    # Print every 100 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}')\n",
    "                running_loss = 0.0\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Training completed in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "def test(model, testloader):\n",
    "    start_time = time.time()\n",
    "    # Testing the best model on test data\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'testing finished in {elapsed_time:.2f} seconds, Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d489527b",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf05816",
   "metadata": {},
   "source": [
    "### Regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6470d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 100] loss: 2.304\n",
      "[1, 200] loss: 2.300\n",
      "[1, 300] loss: 2.284\n",
      "[1, 400] loss: 2.196\n",
      "[1, 500] loss: 2.106\n",
      "[1, 600] loss: 2.075\n",
      "[1, 700] loss: 2.014\n",
      "[2, 100] loss: 1.891\n",
      "[2, 200] loss: 1.880\n",
      "[2, 300] loss: 1.792\n",
      "[2, 400] loss: 1.738\n",
      "[2, 500] loss: 1.696\n",
      "[2, 600] loss: 1.701\n",
      "[2, 700] loss: 1.647\n",
      "[3, 100] loss: 1.567\n",
      "[3, 200] loss: 1.567\n",
      "[3, 300] loss: 1.560\n",
      "[3, 400] loss: 1.544\n",
      "[3, 500] loss: 1.501\n",
      "[3, 600] loss: 1.472\n",
      "[3, 700] loss: 1.479\n",
      "[4, 100] loss: 1.431\n",
      "[4, 200] loss: 1.426\n",
      "[4, 300] loss: 1.387\n",
      "[4, 400] loss: 1.404\n",
      "[4, 500] loss: 1.389\n",
      "[4, 600] loss: 1.402\n",
      "[4, 700] loss: 1.342\n",
      "[5, 100] loss: 1.343\n",
      "[5, 200] loss: 1.288\n",
      "[5, 300] loss: 1.308\n",
      "[5, 400] loss: 1.304\n",
      "[5, 500] loss: 1.296\n",
      "[5, 600] loss: 1.284\n",
      "[5, 700] loss: 1.254\n",
      "[6, 100] loss: 1.252\n",
      "[6, 200] loss: 1.223\n",
      "[6, 300] loss: 1.227\n",
      "[6, 400] loss: 1.207\n",
      "[6, 500] loss: 1.200\n",
      "[6, 600] loss: 1.234\n",
      "[6, 700] loss: 1.241\n",
      "[7, 100] loss: 1.151\n",
      "[7, 200] loss: 1.174\n",
      "[7, 300] loss: 1.160\n",
      "[7, 400] loss: 1.154\n",
      "[7, 500] loss: 1.147\n",
      "[7, 600] loss: 1.184\n",
      "[7, 700] loss: 1.181\n",
      "[8, 100] loss: 1.107\n",
      "[8, 200] loss: 1.073\n",
      "[8, 300] loss: 1.127\n",
      "[8, 400] loss: 1.101\n",
      "[8, 500] loss: 1.126\n",
      "[8, 600] loss: 1.140\n",
      "[8, 700] loss: 1.104\n",
      "[9, 100] loss: 1.064\n",
      "[9, 200] loss: 1.055\n",
      "[9, 300] loss: 1.072\n",
      "[9, 400] loss: 1.085\n",
      "[9, 500] loss: 1.058\n",
      "[9, 600] loss: 1.058\n",
      "[9, 700] loss: 1.102\n",
      "[10, 100] loss: 1.028\n",
      "[10, 200] loss: 1.018\n",
      "[10, 300] loss: 1.020\n",
      "[10, 400] loss: 1.002\n",
      "[10, 500] loss: 1.028\n",
      "[10, 600] loss: 1.036\n",
      "[10, 700] loss: 1.022\n",
      "[11, 100] loss: 0.955\n",
      "[11, 200] loss: 0.980\n",
      "[11, 300] loss: 0.961\n",
      "[11, 400] loss: 0.975\n",
      "[11, 500] loss: 0.999\n",
      "[11, 600] loss: 0.998\n",
      "[11, 700] loss: 1.020\n",
      "[12, 100] loss: 0.902\n",
      "[12, 200] loss: 0.939\n",
      "[12, 300] loss: 0.956\n",
      "[12, 400] loss: 0.977\n",
      "[12, 500] loss: 0.962\n",
      "[12, 600] loss: 0.976\n",
      "[12, 700] loss: 0.963\n",
      "[13, 100] loss: 0.893\n",
      "[13, 200] loss: 0.903\n",
      "[13, 300] loss: 0.907\n",
      "[13, 400] loss: 0.933\n",
      "[13, 500] loss: 0.938\n",
      "[13, 600] loss: 0.980\n",
      "[13, 700] loss: 0.932\n",
      "[14, 100] loss: 0.858\n",
      "[14, 200] loss: 0.850\n",
      "[14, 300] loss: 0.855\n",
      "[14, 400] loss: 0.894\n",
      "[14, 500] loss: 0.898\n",
      "[14, 600] loss: 0.916\n",
      "[14, 700] loss: 0.916\n",
      "[15, 100] loss: 0.816\n",
      "[15, 200] loss: 0.837\n",
      "[15, 300] loss: 0.853\n",
      "[15, 400] loss: 0.850\n",
      "[15, 500] loss: 0.871\n",
      "[15, 600] loss: 0.895\n",
      "[15, 700] loss: 0.880\n",
      "[16, 100] loss: 0.811\n",
      "[16, 200] loss: 0.815\n",
      "[16, 300] loss: 0.837\n",
      "[16, 400] loss: 0.864\n",
      "[16, 500] loss: 0.834\n",
      "[16, 600] loss: 0.861\n",
      "[16, 700] loss: 0.866\n",
      "[17, 100] loss: 0.750\n",
      "[17, 200] loss: 0.780\n",
      "[17, 300] loss: 0.810\n",
      "[17, 400] loss: 0.811\n",
      "[17, 500] loss: 0.831\n",
      "[17, 600] loss: 0.872\n",
      "[17, 700] loss: 0.831\n",
      "[18, 100] loss: 0.745\n",
      "[18, 200] loss: 0.749\n",
      "[18, 300] loss: 0.773\n",
      "[18, 400] loss: 0.823\n",
      "[18, 500] loss: 0.803\n",
      "[18, 600] loss: 0.854\n",
      "[18, 700] loss: 0.831\n",
      "[19, 100] loss: 0.713\n",
      "[19, 200] loss: 0.740\n",
      "[19, 300] loss: 0.741\n",
      "[19, 400] loss: 0.768\n",
      "[19, 500] loss: 0.784\n",
      "[19, 600] loss: 0.809\n",
      "[19, 700] loss: 0.833\n",
      "[20, 100] loss: 0.695\n",
      "[20, 200] loss: 0.716\n",
      "[20, 300] loss: 0.721\n",
      "[20, 400] loss: 0.765\n",
      "[20, 500] loss: 0.752\n",
      "[20, 600] loss: 0.789\n",
      "[20, 700] loss: 0.793\n",
      "Training completed in 66.10 seconds\n"
     ]
    }
   ],
   "source": [
    "model = LeNet().to(device)\n",
    "# DataLoader for training and test datasets\n",
    "trainloader = torch.utils.data.DataLoader(cifar_trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(cifar_testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train(model, trainloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9ffb83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing finished in 0.51 seconds, Accuracy: 57.36%\n"
     ]
    }
   ],
   "source": [
    "test(model, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552bc6a0",
   "metadata": {},
   "source": [
    "### With Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a71c037f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 100] loss: 2.304\n",
      "[1, 200] loss: 2.300\n",
      "[1, 300] loss: 2.268\n",
      "[1, 400] loss: 2.134\n",
      "[1, 500] loss: 2.056\n",
      "[1, 600] loss: 1.990\n",
      "[1, 700] loss: 1.939\n",
      "[2, 100] loss: 1.819\n",
      "[2, 200] loss: 1.743\n",
      "[2, 300] loss: 1.727\n",
      "[2, 400] loss: 1.718\n",
      "[2, 500] loss: 1.698\n",
      "[2, 600] loss: 1.642\n",
      "[2, 700] loss: 1.643\n",
      "[3, 100] loss: 1.597\n",
      "[3, 200] loss: 1.569\n",
      "[3, 300] loss: 1.547\n",
      "[3, 400] loss: 1.554\n",
      "[3, 500] loss: 1.586\n",
      "[3, 600] loss: 1.551\n",
      "[3, 700] loss: 1.544\n",
      "[4, 100] loss: 1.513\n",
      "[4, 200] loss: 1.482\n",
      "[4, 300] loss: 1.473\n",
      "[4, 400] loss: 1.465\n",
      "[4, 500] loss: 1.463\n",
      "[4, 600] loss: 1.453\n",
      "[4, 700] loss: 1.472\n",
      "[5, 100] loss: 1.410\n",
      "[5, 200] loss: 1.398\n",
      "[5, 300] loss: 1.430\n",
      "[5, 400] loss: 1.420\n",
      "[5, 500] loss: 1.414\n",
      "[5, 600] loss: 1.383\n",
      "[5, 700] loss: 1.392\n",
      "[6, 100] loss: 1.374\n",
      "[6, 200] loss: 1.371\n",
      "[6, 300] loss: 1.359\n",
      "[6, 400] loss: 1.351\n",
      "[6, 500] loss: 1.369\n",
      "[6, 600] loss: 1.364\n",
      "[6, 700] loss: 1.371\n",
      "[7, 100] loss: 1.339\n",
      "[7, 200] loss: 1.319\n",
      "[7, 300] loss: 1.294\n",
      "[7, 400] loss: 1.319\n",
      "[7, 500] loss: 1.312\n",
      "[7, 600] loss: 1.315\n",
      "[7, 700] loss: 1.299\n",
      "[8, 100] loss: 1.285\n",
      "[8, 200] loss: 1.270\n",
      "[8, 300] loss: 1.303\n",
      "[8, 400] loss: 1.286\n",
      "[8, 500] loss: 1.293\n",
      "[8, 600] loss: 1.289\n",
      "[8, 700] loss: 1.296\n",
      "[9, 100] loss: 1.266\n",
      "[9, 200] loss: 1.278\n",
      "[9, 300] loss: 1.270\n",
      "[9, 400] loss: 1.264\n",
      "[9, 500] loss: 1.275\n",
      "[9, 600] loss: 1.233\n",
      "[9, 700] loss: 1.269\n",
      "[10, 100] loss: 1.234\n",
      "[10, 200] loss: 1.222\n",
      "[10, 300] loss: 1.222\n",
      "[10, 400] loss: 1.252\n",
      "[10, 500] loss: 1.246\n",
      "[10, 600] loss: 1.227\n",
      "[10, 700] loss: 1.242\n",
      "[11, 100] loss: 1.207\n",
      "[11, 200] loss: 1.211\n",
      "[11, 300] loss: 1.210\n",
      "[11, 400] loss: 1.225\n",
      "[11, 500] loss: 1.241\n",
      "[11, 600] loss: 1.228\n",
      "[11, 700] loss: 1.223\n",
      "[12, 100] loss: 1.184\n",
      "[12, 200] loss: 1.222\n",
      "[12, 300] loss: 1.183\n",
      "[12, 400] loss: 1.210\n",
      "[12, 500] loss: 1.210\n",
      "[12, 600] loss: 1.198\n",
      "[12, 700] loss: 1.197\n",
      "[13, 100] loss: 1.165\n",
      "[13, 200] loss: 1.178\n",
      "[13, 300] loss: 1.227\n",
      "[13, 400] loss: 1.197\n",
      "[13, 500] loss: 1.199\n",
      "[13, 600] loss: 1.191\n",
      "[13, 700] loss: 1.175\n",
      "[14, 100] loss: 1.171\n",
      "[14, 200] loss: 1.172\n",
      "[14, 300] loss: 1.181\n",
      "[14, 400] loss: 1.181\n",
      "[14, 500] loss: 1.173\n",
      "[14, 600] loss: 1.173\n",
      "[14, 700] loss: 1.178\n",
      "[15, 100] loss: 1.168\n",
      "[15, 200] loss: 1.166\n",
      "[15, 300] loss: 1.139\n",
      "[15, 400] loss: 1.179\n",
      "[15, 500] loss: 1.168\n",
      "[15, 600] loss: 1.162\n",
      "[15, 700] loss: 1.162\n",
      "[16, 100] loss: 1.144\n",
      "[16, 200] loss: 1.135\n",
      "[16, 300] loss: 1.147\n",
      "[16, 400] loss: 1.136\n",
      "[16, 500] loss: 1.164\n",
      "[16, 600] loss: 1.152\n",
      "[16, 700] loss: 1.158\n",
      "[17, 100] loss: 1.129\n",
      "[17, 200] loss: 1.125\n",
      "[17, 300] loss: 1.140\n",
      "[17, 400] loss: 1.138\n",
      "[17, 500] loss: 1.158\n",
      "[17, 600] loss: 1.116\n",
      "[17, 700] loss: 1.182\n",
      "[18, 100] loss: 1.136\n",
      "[18, 200] loss: 1.108\n",
      "[18, 300] loss: 1.119\n",
      "[18, 400] loss: 1.118\n",
      "[18, 500] loss: 1.159\n",
      "[18, 600] loss: 1.125\n",
      "[18, 700] loss: 1.160\n",
      "[19, 100] loss: 1.116\n",
      "[19, 200] loss: 1.105\n",
      "[19, 300] loss: 1.092\n",
      "[19, 400] loss: 1.117\n",
      "[19, 500] loss: 1.123\n",
      "[19, 600] loss: 1.135\n",
      "[19, 700] loss: 1.161\n",
      "[20, 100] loss: 1.115\n",
      "[20, 200] loss: 1.125\n",
      "[20, 300] loss: 1.106\n",
      "[20, 400] loss: 1.068\n",
      "[20, 500] loss: 1.131\n",
      "[20, 600] loss: 1.116\n",
      "[20, 700] loss: 1.121\n",
      "Training completed in 65.90 seconds\n"
     ]
    }
   ],
   "source": [
    "model1 = LeNet_v1().to(device)\n",
    "# DataLoader for training and test datasets\n",
    "trainloader = torch.utils.data.DataLoader(cifar_trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(cifar_testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train(model1, trainloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96750a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing finished in 0.51 seconds, Accuracy: 59.54%\n"
     ]
    }
   ],
   "source": [
    "test(model1, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a440392",
   "metadata": {},
   "source": [
    "### With Dropout and Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d83d1e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 100] loss: 2.173\n",
      "[1, 200] loss: 1.873\n",
      "[1, 300] loss: 1.765\n",
      "[1, 400] loss: 1.705\n",
      "[1, 500] loss: 1.658\n",
      "[1, 600] loss: 1.638\n",
      "[1, 700] loss: 1.566\n",
      "[2, 100] loss: 1.535\n",
      "[2, 200] loss: 1.528\n",
      "[2, 300] loss: 1.513\n",
      "[2, 400] loss: 1.481\n",
      "[2, 500] loss: 1.493\n",
      "[2, 600] loss: 1.454\n",
      "[2, 700] loss: 1.429\n",
      "[3, 100] loss: 1.398\n",
      "[3, 200] loss: 1.391\n",
      "[3, 300] loss: 1.383\n",
      "[3, 400] loss: 1.424\n",
      "[3, 500] loss: 1.399\n",
      "[3, 600] loss: 1.378\n",
      "[3, 700] loss: 1.337\n",
      "[4, 100] loss: 1.356\n",
      "[4, 200] loss: 1.320\n",
      "[4, 300] loss: 1.314\n",
      "[4, 400] loss: 1.310\n",
      "[4, 500] loss: 1.301\n",
      "[4, 600] loss: 1.316\n",
      "[4, 700] loss: 1.293\n",
      "[5, 100] loss: 1.271\n",
      "[5, 200] loss: 1.260\n",
      "[5, 300] loss: 1.299\n",
      "[5, 400] loss: 1.262\n",
      "[5, 500] loss: 1.245\n",
      "[5, 600] loss: 1.255\n",
      "[5, 700] loss: 1.246\n",
      "[6, 100] loss: 1.222\n",
      "[6, 200] loss: 1.216\n",
      "[6, 300] loss: 1.233\n",
      "[6, 400] loss: 1.206\n",
      "[6, 500] loss: 1.223\n",
      "[6, 600] loss: 1.239\n",
      "[6, 700] loss: 1.189\n",
      "[7, 100] loss: 1.170\n",
      "[7, 200] loss: 1.187\n",
      "[7, 300] loss: 1.197\n",
      "[7, 400] loss: 1.183\n",
      "[7, 500] loss: 1.179\n",
      "[7, 600] loss: 1.192\n",
      "[7, 700] loss: 1.176\n",
      "[8, 100] loss: 1.147\n",
      "[8, 200] loss: 1.162\n",
      "[8, 300] loss: 1.168\n",
      "[8, 400] loss: 1.144\n",
      "[8, 500] loss: 1.167\n",
      "[8, 600] loss: 1.184\n",
      "[8, 700] loss: 1.138\n",
      "[9, 100] loss: 1.132\n",
      "[9, 200] loss: 1.141\n",
      "[9, 300] loss: 1.144\n",
      "[9, 400] loss: 1.139\n",
      "[9, 500] loss: 1.145\n",
      "[9, 600] loss: 1.127\n",
      "[9, 700] loss: 1.139\n",
      "[10, 100] loss: 1.113\n",
      "[10, 200] loss: 1.085\n",
      "[10, 300] loss: 1.121\n",
      "[10, 400] loss: 1.108\n",
      "[10, 500] loss: 1.109\n",
      "[10, 600] loss: 1.132\n",
      "[10, 700] loss: 1.122\n",
      "[11, 100] loss: 1.102\n",
      "[11, 200] loss: 1.108\n",
      "[11, 300] loss: 1.097\n",
      "[11, 400] loss: 1.080\n",
      "[11, 500] loss: 1.098\n",
      "[11, 600] loss: 1.101\n",
      "[11, 700] loss: 1.113\n",
      "[12, 100] loss: 1.080\n",
      "[12, 200] loss: 1.060\n",
      "[12, 300] loss: 1.126\n",
      "[12, 400] loss: 1.061\n",
      "[12, 500] loss: 1.072\n",
      "[12, 600] loss: 1.085\n",
      "[12, 700] loss: 1.111\n",
      "[13, 100] loss: 1.049\n",
      "[13, 200] loss: 1.056\n",
      "[13, 300] loss: 1.074\n",
      "[13, 400] loss: 1.054\n",
      "[13, 500] loss: 1.080\n",
      "[13, 600] loss: 1.071\n",
      "[13, 700] loss: 1.090\n",
      "[14, 100] loss: 1.042\n",
      "[14, 200] loss: 1.051\n",
      "[14, 300] loss: 1.063\n",
      "[14, 400] loss: 1.066\n",
      "[14, 500] loss: 1.056\n",
      "[14, 600] loss: 1.068\n",
      "[14, 700] loss: 1.080\n",
      "[15, 100] loss: 1.032\n",
      "[15, 200] loss: 1.031\n",
      "[15, 300] loss: 1.046\n",
      "[15, 400] loss: 1.049\n",
      "[15, 500] loss: 1.053\n",
      "[15, 600] loss: 1.095\n",
      "[15, 700] loss: 1.045\n",
      "[16, 100] loss: 1.018\n",
      "[16, 200] loss: 1.029\n",
      "[16, 300] loss: 1.035\n",
      "[16, 400] loss: 1.069\n",
      "[16, 500] loss: 1.032\n",
      "[16, 600] loss: 1.043\n",
      "[16, 700] loss: 1.035\n",
      "[17, 100] loss: 1.000\n",
      "[17, 200] loss: 1.002\n",
      "[17, 300] loss: 1.018\n",
      "[17, 400] loss: 1.020\n",
      "[17, 500] loss: 1.015\n",
      "[17, 600] loss: 1.037\n",
      "[17, 700] loss: 1.049\n",
      "[18, 100] loss: 0.987\n",
      "[18, 200] loss: 1.005\n",
      "[18, 300] loss: 1.016\n",
      "[18, 400] loss: 1.038\n",
      "[18, 500] loss: 1.043\n",
      "[18, 600] loss: 1.014\n",
      "[18, 700] loss: 1.040\n",
      "[19, 100] loss: 0.986\n",
      "[19, 200] loss: 1.000\n",
      "[19, 300] loss: 0.967\n",
      "[19, 400] loss: 1.008\n",
      "[19, 500] loss: 1.024\n",
      "[19, 600] loss: 1.026\n",
      "[19, 700] loss: 1.034\n",
      "[20, 100] loss: 0.994\n",
      "[20, 200] loss: 1.009\n",
      "[20, 300] loss: 1.005\n",
      "[20, 400] loss: 0.990\n",
      "[20, 500] loss: 1.031\n",
      "[20, 600] loss: 1.027\n",
      "[20, 700] loss: 0.998\n",
      "Training completed in 67.51 seconds\n"
     ]
    }
   ],
   "source": [
    "model2 = LeNet_v2().to(device)\n",
    "# DataLoader for training and test datasets\n",
    "trainloader = torch.utils.data.DataLoader(cifar_trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(cifar_testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train(model2, trainloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a8bf98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing finished in 0.50 seconds, Accuracy: 64.52%\n"
     ]
    }
   ],
   "source": [
    "test(model2, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3b7226",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fb078e",
   "metadata": {},
   "source": [
    "I used a batch size of 64, as it gave me better performance than 128, 256. The smaller batch size allowed for more frequent weight updates, which helped the model navigate the loss landscape more effectively. While larger batches could potentially use GPU resources more efficiently, the 64 batch size struck the right balance between computational efficiency and learning dynamics for this CIFAR-10 classification task.\n",
    "\n",
    "The learning rate of 0.01 with SGD optimizer and momentum of 0.9 provided stable convergence without oscillation issues. Training for 20 epochs was sufficient to demonstrate the differences between the model variations while avoiding overfitting in the base model.\n",
    "\n",
    "### Dropout\n",
    "Adding dropout to the LeNet architecture shows significant improvement in preventing overfitting:\n",
    "- Acts as a regularization technique by randomly \"dropping\" neurons during training\n",
    "- Forces the network to learn more robust features that don't rely on specific neurons\n",
    "- Creates an implicit ensemble effect, as each training iteration uses a different subset of neurons\n",
    "\n",
    "### Dropout + Batch Normalization\n",
    "Combining dropout with batch normalization further enhances model performance:\n",
    "- Batch normalization stabilizes the learning process by normalizing layer inputs\n",
    "- Reduces internal covariate shift, allowing for higher learning rates\n",
    "- Works synergistically with dropout to improve both training speed and generalization\n",
    "- Helps mitigate vanishing/exploding gradient problems in deeper networks\n",
    "\n",
    "These did not improve the accuracy too much, but a win is a win\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
